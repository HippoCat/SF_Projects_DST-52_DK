# SF_Projects_DST-52_DK/module_03_TripAdvisor_Restaurants

В этом репозитории хранится решениe "Проект 3. О вкусной и здоровой пище".

Задача создать свой первый кейс по машинному обучению: самостоятельно очистить довольно сильно загрязнённый датасет, извлечь из него несколько новых признаков и подготовитьи данные для обучения модели.

Также  принять участие в первом соревновании по машинному обучению и вступить в самое большое в мире сообщество действующих Data Scientist'ов. 


Дмитрий Кузнецов, поток DST-52 (SkillFactory), 21-26 Мая 2021



## Рекомендованная последовательность действий от организаторов


- разобраться с подробным описанием того, как будет организовано изучение модуля;
- зарегистрироваться в соревновании на kaggle;
- проанализировать baseline к соревнованию;
- следуя подсказкам в модуле, обработать оставшиеся признаки и подготовить собственное решение;
- победить в соревновании :)

_"Не пугайтесь, вам не придётся совершать академический подвиг и изучать машинное обучение в экстремально короткие сроки! На самом деле код для создания и обучения модели мы вам предоставим в готовом виде, и этот код будет довольно простым: в нём не будет предусмотрен подбор параметров и тонкая настройка модели (всему этому вы научитесь позже, в курсе по ML). Пока ваша задача будет состоять в том, чтобы качественно подготовить данные для обучения модели. Скоро вы убедитесь, что тщательная очистка данных и генерация новых признаков (Feature Engineering) способны повысить точность модели в два и более раз, и владение этими навыками играют в машинном обучении не меньшую роль, чем умение выбрать алгоритм и настроить модель."_


## Что сделал


1. Заполнил пропуски в 'Number of Reviews' медианой по городу. Заполнение медианой дает лучшую MAE, чем заполнение средним значением
2. Заполнил пропуски в 'Price Range' случайными значениями используя np.random.choice([1,2,3], p=[0.24, 0.71, 0.05]), где p - распределение цен в среднем по датасету. Заполнять просто средним или медианой не хотелось, ибо что одно, что другое равно 2, то есть соответствует средней ценовой категории.
3. Преобразовал 'Cuisine Style' в список и на его основе создал столбец 'Number of Cuisines' - просто по длине списка.
4. Если список 'Cuisine Style' пустой, то пробовал заполнять его либо средним, либо медианным значением количество кухонь в городе. Однако в обоих случаях MAE ухудшалось.
5. Поэтому в результате просто заполнил пропуски (т.е. в случае пустых списков) единицей - 1.
6. В __идеале__ надо уметь парсить сайт в поисках доп инфы в случае пропусков. Так например, можно используя URL из датасета вытащить с сайта недостающую инфу о 'Number of Reviews', 'Price Range', 'Cuisine Style' и пр.
7. В связи с отсутствием навыка и недостатком времени не стал делать п.6
8. Добавил инфу из внешних источников: из Wikipedia о населении городов, и из TripAdvisor о количестве ресторанов в городе. Создал соответствующие колонки в датасете.
9. Расшифровал колонку с двумя (или менее) отзывами. Сделал вместо нее 4 колонки ['review_1', 'review_2', 'date_1', 'date_2']
10. Посчитал количество дней между отзывами, добавил колонку 'Days', MAE улучшилась.
11. Добавил анализ тональности двух 'Reviews' в Python с помощью TextBlob, локально MAE улучшилась незначительно.


## Хронология локальной MAE


- 25.05. 19:00 MAE: 0.213073
- 25.05. 19:50 MAE: 0.213991 - нормализовал Ranking, стало чуть хуже
- 25.05. 19:50 MAE: 0.213283 - вернул как было, т.е. без нормализации Ranking
- 25.05. 20:30 MAE: 0.212594 - добавил столбец 'Restaurants_per_Thousand'
- 25.05. 20:45 MAE: 0.213574 - вернул нормализацию Ranking
- 25.05. 20:45 MAE: 0.213273 - вернул нормализацию Ranking + удалил изначальный "ненормальный" столбец 'Ranking'
- 26.05. 01:10 MAE: 0.214641 - сделал заполнение Price Range пропорционально вероятностям, но MAE ухудшился :-(
- 26.05. 01:30 MAE: 0.213427 - вроде ничего не менял, а MAE слегка улучшился...
- 26.05. 01:35 MAE: 0.187563 - всего-то навсего (полу)округлил y_pred с точностью до 0.5... Ничего себе?...
- 26.05. 13:45 MAE: 0.187188 - ничего не менял... Почему-то ошибка немного уменьшилась
- 26.05. 13:45 MAE: 0.183875 - заполнил пропуски в 'Number of Reviews' не на mean, как в Baseline, а на median
- 26.05. 15:50 MAE: 0.186063 - заполнил пропуски в 'Number of Cuisines' на mean по городу
- 26.05. 15:55 MAE: 0.183625 - заполнил пропуски в 'Number of Cuisines' на 1 - MAE лучше, чем при замене на mean
- 26.05. 16:40 MAE: 0.181313 - добавил 'Ranking by Number of Reviews' - БЕЗ нормализации, нормализация ухудшает MAE
- 26.05. 16:50 MAE: 0.183313 - 'Reviews per Population' - БЕЗ нормализации
- 26.05. 17:00 MAE: 0.181750 - убрал 'Reviews per Population'
- 26.05. 18:45 MAE: 0.177250 - добавил колонку 'Days' - количество дней между двумя отзывами
- 26.05. 19:05 MAE: 0.175313 - добавил анализ тональности двух 'Reviews' в Python с помощью TextBlob


## Комментарии на будущее

Что можно улучшать:

1. Больше времени оставлять на проекты, 5 дней уже недостаточно. Минимум - полная неделя!;
2. Многие рутинные вещи занимают много времени, нужно больше практики. Часто упираешься просто в собственные "тупые" ошибки, из-за которых тратишь много времени впустую и расстраиваешься из-за собственной глупости; 
3. Для задач подобного рода очень важно уметь парсить сайты в поисках нелостающей инфы - в нашем случае  'Number of Reviews', 'Price Range', 'Cuisine Style' и пр.;
4. Анализ тональности всего двух отзывов вряд ли репрезентативен. В идеале - скачать все доступные отзывы и провести аналих их тональности. Сам анализ текстовой информации вполне ожидаемо занимает много времени. В моем случае TextBlob анализировал по 2 отзыва для 50,000 ресторанов пару минут.



Буду рад любой обратной связи, замечаниям и конструктивной критике об этом проекте, как от команды курса SkillFactory, так и от коллег однокурсников.

Заранее благодарен.

Д.К.
26 Мая 2021, 18:00